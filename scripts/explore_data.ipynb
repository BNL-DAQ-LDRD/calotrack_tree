{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48e4ed8-c992-40dd-b661-bc2366a8405c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# https://github.com/BNL-DAQ-LDRD/calotrack_tree/tree/main\n",
    "# enum detid {\n",
    "#     mvtxId = 0,\n",
    "#     inttId = 1,\n",
    "#     tpcId = 2,\n",
    "#     tpotId = 3,\n",
    "#     cemcId = 4,\n",
    "#     ihcalId = 5,\n",
    "#     ohcalId = 6,\n",
    "#     epdId = 7,\n",
    "#     mbdId = 8\n",
    "# };\n",
    "\n",
    "# input hits in calarometer is \"nHits_\", and in trackers \"reco_cluster_\"\n",
    "# groundtruth hits in calarometer is \"particle_\" and in trackers \"truth_cluster_\"\n",
    "data_file = \"macro/testout.root\" # sample data shared by Shuhang containing 100 events\n",
    "event_id = 0  # pick different events\n",
    "with uproot.open(data_file) as fp:\n",
    "    print(list(fp['T;1'].keys()))\n",
    "data = uproot.open(data_file)[\"T;1\"]\n",
    "detid = {\"mvtx\": 0,\"intt\": 1,\"tpc\": 2,\"tpot\": 3,\"cemc\": 4,\"ihcal\": 5,\"ohcal\": 6,\"epd\": 7,\"mbd\": 8 };\n",
    "id2det = {x:str(x)+'-'+y for y,x in detid.items()}\n",
    "## combine all hits and clusters per event\n",
    "def get_event(event_id):\n",
    "    calx = data[\"Hit_x\"].array(library=\"np\")[event_id]\n",
    "    caly = data[\"Hit_y\"].array(library=\"np\")[event_id]\n",
    "    calz = data[\"Hit_z\"].array(library=\"np\")[event_id]\n",
    "    calE = data[\"Hit_E\"].array(library=\"np\")[event_id]\n",
    "    calD = data[\"Hit_detid\"].array(library=\"np\")[event_id]\n",
    "    trkx = data[\"reco_cluster_x\"].array(library=\"np\")[event_id]\n",
    "    trky = data[\"reco_cluster_y\"].array(library=\"np\")[event_id]\n",
    "    trkz = data[\"reco_cluster_z\"].array(library=\"np\")[event_id]\n",
    "    trkE = data[\"reco_cluster_E\"].array(library=\"np\")[event_id]\n",
    "    trkD = data[\"reco_cluster_detid\"].array(library=\"np\")[event_id]\n",
    "    trk_g4hit_trkid = data[\"reco_cluster_g4hit_trkid\"].array(library=\"np\")[event_id]\n",
    "    x = np.concatenate([trkx])\n",
    "    y = np.concatenate([trky])\n",
    "    z = np.concatenate([trkz])\n",
    "    E = np.concatenate([trkE])\n",
    "    D = np.concatenate([trkD])\n",
    "    g4hit_trkid = np.concatenate([trk_g4hit_trkid])\n",
    "    # x = np.concatenate([trkx, calx])\n",
    "    # y = np.concatenate([trky, caly])\n",
    "    # z = np.concatenate([trkz, calz])\n",
    "    # E = np.concatenate([trkE, calE])\n",
    "    # D = np.concatenate([trkD, calD])\n",
    "    df = pd.DataFrame({\"x\": x, \"y\": y, \"z\": z, \"E\": E, \"D\": D, \"g4hit_trkid\": g4hit_trkid})\n",
    "    df[\"detector type\"] = df[\"D\"].apply(lambda x: id2det[x])\n",
    "    # df = df[(df['g4hit_trkid'] < 100)]\n",
    "    return df\n",
    "\n",
    "## Pie Chart of number of \"hits\" and \"clusters\" from different detectors\n",
    "df = get_event(event_id)\n",
    "tmp = df[\"detector type\"].to_list();\n",
    "a, b= np.unique(tmp, return_counts=True)\n",
    "tmp_df = pd.DataFrame({'name': a, 'count': b})\n",
    "fig = px.pie(tmp_df, values='count', names='name')\n",
    "fig.update_layout(legend_traceorder=\"normal\")\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n",
    "fig = px.scatter(\n",
    "    df,\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    color=\"g4hit_trkid\",\n",
    "    title=\"Reco Clusters\"\n",
    ")\n",
    "fig.update_layout(\n",
    "    xaxis=dict(range=[-80, 80]),\n",
    "    yaxis=dict(\n",
    "        scaleanchor=\"x\",\n",
    "        scaleratio=1,\n",
    "        range=[-80, 80]\n",
    "    )\n",
    ")\n",
    "fig.update_traces(marker_size=3)\n",
    "fig.show()\n",
    "\n",
    "fig = px.scatter_3d(df, x='x', y='y', z='z', color='g4hit_trkid', opacity=0.3)#, symbol='D')\n",
    "fig.update_traces(marker_size=3)\n",
    "fig.update_layout(title=f\"event {event_id}\", width=800, height=800)\n",
    "camera = dict(\n",
    "    up=dict(x=1, y=0, z=0),\n",
    "    center=dict(x=0, y=0, z=0),\n",
    "    eye=dict(x=1.25, y=1.25, z=1.25)\n",
    ")\n",
    "fig.update_layout(scene_camera=camera, title=f\"EventID={event_id}\")\n",
    "fig.update_layout(legend_traceorder=\"normal\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d526fa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clusters(data, event_id):\n",
    "    cid = data[\"reco_cluster_id\"].array(library=\"np\")[event_id]\n",
    "    x = data[\"reco_cluster_x\"].array(library=\"np\")[event_id]\n",
    "    y = data[\"reco_cluster_y\"].array(library=\"np\")[event_id]\n",
    "    z = data[\"reco_cluster_z\"].array(library=\"np\")[event_id]\n",
    "    detid = data[\"reco_cluster_detid\"].array(library=\"np\")[event_id]\n",
    "    pid = data[\"reco_cluster_g4hit_trkid\"].array(library=\"np\")[event_id]\n",
    "    df = pd.DataFrame({\"cid\": cid, \"x\": x, \"y\": y, \"z\": z, \"detid\": detid, \"pid\": pid})\n",
    "    return df\n",
    "\n",
    "clusters = get_clusters(data, 0)\n",
    "cid_to_index = {cid: index for index, cid in enumerate(clusters['cid'])}\n",
    "pid_to_cids = clusters.groupby('pid')['cid'].apply(list).to_dict()\n",
    "\n",
    "print(f\"Number of clusters: {len(clusters)}\")\n",
    "print(list(pid_to_cids.items())[0])\n",
    "for i in range(10):\n",
    "    print(list(pid_to_cids.items())[i])\n",
    "\n",
    "clusters[clusters[\"pid\"] < 1e8][\"pid\"].plot(kind=\"hist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eda8291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seeds(data, event_id):\n",
    "    sid = data[\"tpc_seeds_id\"].array(library=\"np\")[event_id]\n",
    "    cids = data[\"tpc_seeds_clusters\"].array(library=\"np\")[event_id]\n",
    "    ncid = data[\"tpc_seeds_nclusters\"].array(library=\"np\")[event_id]\n",
    "    cid_start = data[\"tpc_seeds_start_idx\"].array(library=\"np\")[event_id]\n",
    "    list_of_cids = [cids[start : start + length] \n",
    "                for start, length in zip(cid_start, ncid)]\n",
    "    lists_of_x = [[clusters.iloc[cid_to_index[cid]]['x'] for cid in cids] for cids in list_of_cids]\n",
    "    lists_of_y = [[clusters.iloc[cid_to_index[cid]]['y'] for cid in cids] for cids in list_of_cids]\n",
    "    lists_of_z = [[clusters.iloc[cid_to_index[cid]]['z'] for cid in cids] for cids in list_of_cids]\n",
    "    df = pd.DataFrame({\"sid\": sid, \"cids\": list_of_cids, \"x\": lists_of_x, \"y\": lists_of_y, \"z\": lists_of_z})\n",
    "    return df\n",
    "\n",
    "seeds = get_seeds(data, 0)\n",
    "print(f\"Number of seeds: {len(seeds)}\")\n",
    "print(seeds.iloc[0])\n",
    "\n",
    "# Flatten the lists in seeds DataFrame so that each row is one cluster point,\n",
    "# and include the seed id for grouping.\n",
    "flattened_data = {\"seed\": [], \"x\": [], \"y\": [], \"z\": [], \"r\": []}\n",
    "for irow, row in seeds.iterrows():\n",
    "    # if irow % 100  != 0:\n",
    "    #     continue\n",
    "    for x_val, y_val, z_val in zip(row[\"x\"], row[\"y\"], row[\"z\"]):\n",
    "        flattened_data[\"seed\"].append(row[\"sid\"])\n",
    "        flattened_data[\"x\"].append(x_val)\n",
    "        flattened_data[\"y\"].append(y_val)\n",
    "        flattened_data[\"z\"].append(z_val)\n",
    "        flattened_data[\"r\"].append(np.sqrt(x_val**2 + y_val**2))\n",
    "\n",
    "df_flat = pd.DataFrame(flattened_data)\n",
    "df_flat[\"r\"].plot(kind=\"hist\")\n",
    "\n",
    "fig = px.scatter(\n",
    "    df_flat,\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    color=\"seed\",\n",
    "    title=\"Seed Clusters\"\n",
    ")\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        range=[-80, 80],\n",
    "        gridcolor='lightgray',\n",
    "        ),\n",
    "    yaxis=dict(\n",
    "        scaleanchor=\"x\",\n",
    "        scaleratio=1,\n",
    "        range=[-80, 80],\n",
    "        gridcolor='lightgray',\n",
    "    ),\n",
    "    paper_bgcolor='white',\n",
    "    plot_bgcolor='white',\n",
    ")\n",
    "fig.update_traces(marker_size=3)\n",
    "fig.show()\n",
    "\n",
    "fig = px.scatter_3d(\n",
    "    df_flat,\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    z=\"z\",\n",
    "    color=\"seed\",\n",
    "    title=\"Seed Clusters\"\n",
    ")\n",
    "fig.update_traces(marker_size=3)\n",
    "fig.update_layout(scene_camera=dict(\n",
    "    eye=dict(x=0, y=0, z=2)\n",
    "))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012aee58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_particles(data, event_id):\n",
    "    pid = data[\"particle_track_id\"].array(library=\"np\")[event_id]\n",
    "    cids = [pid_to_cids.get(p, [])  for p in pid]\n",
    "    lists_of_x = [[clusters.iloc[cid_to_index[cid]]['x'] for cid in cids] for cids in cids]\n",
    "    lists_of_y = [[clusters.iloc[cid_to_index[cid]]['y'] for cid in cids] for cids in cids]\n",
    "    lists_of_z = [[clusters.iloc[cid_to_index[cid]]['z'] for cid in cids] for cids in cids]\n",
    "    px = data[\"particle_px\"].array(library=\"np\")[event_id]\n",
    "    py = data[\"particle_py\"].array(library=\"np\")[event_id]\n",
    "    pz = data[\"particle_pz\"].array(library=\"np\")[event_id]\n",
    "    pt = [np.sqrt(px**2 + py**2) for px, py in zip(px, py)]\n",
    "    df = pd.DataFrame({\"pid\": pid, \"pt\": pt, \"cids\": cids, \"x\": lists_of_x, \"y\": lists_of_y, \"z\": lists_of_z})\n",
    "    # df = df[df['pid'] > 0]\n",
    "    df = df[df['pt'] > 0.5]\n",
    "    # df = df[df['cids'].apply(len) > 30]\n",
    "    return df\n",
    "particles = get_particles(data, event_id)\n",
    "\n",
    "print(f\"Number of particles: {len(particles)}\")\n",
    "for i in range(min(10, len(particles))):\n",
    "    print(f\"pt: {particles.iloc[i]['pt']}, pid: {particles.iloc[i]['pid']}, cids: {len(particles['cids'].iloc[i])}\")\n",
    "\n",
    "particles['pt'].plot(kind='hist')\n",
    "\n",
    "flattened_data = {\"particle\": [], \"x\": [], \"y\": [], \"z\": [], \"r\": []}\n",
    "for irow, row in particles.iterrows():\n",
    "    # if irow % 100 != 0:\n",
    "    #     continue\n",
    "    for x_val, y_val, z_val in zip(row[\"x\"], row[\"y\"], row[\"z\"]):\n",
    "        flattened_data[\"particle\"].append(row[\"pid\"])\n",
    "        flattened_data[\"x\"].append(x_val)\n",
    "        flattened_data[\"y\"].append(y_val)\n",
    "        flattened_data[\"z\"].append(z_val)\n",
    "        flattened_data[\"r\"].append(np.sqrt(x_val**2 + y_val**2))\n",
    "\n",
    "df_flat = pd.DataFrame(flattened_data)\n",
    "df_flat[\"r\"].plot(kind=\"hist\")\n",
    "\n",
    "fig = px.scatter(\n",
    "    df_flat,\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    color=\"particle\",\n",
    "    title=\"Particle Clusters\"\n",
    ")\n",
    "fig.update_layout(\n",
    "    xaxis=dict(range=[-80, 80]),\n",
    "    yaxis=dict(\n",
    "        scaleanchor=\"x\",\n",
    "        scaleratio=1,\n",
    "        range=[-80, 80]\n",
    "    )\n",
    ")\n",
    "fig.update_traces(marker_size=3)\n",
    "fig.show()\n",
    "\n",
    "fig = px.scatter_3d(\n",
    "    df_flat,\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    z=\"z\",\n",
    "    color=\"particle\",\n",
    "    title=\"Particle Clusters\"\n",
    ")\n",
    "fig.update_traces(marker_size=3)\n",
    "fig.update_layout(scene_camera=dict(\n",
    "    eye=dict(x=0, y=0, z=2)\n",
    "))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eae6aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_particles_to_seeds_optimized(particles, seeds, ncommon):\n",
    "    \"\"\"\n",
    "    For each particle in the particles DataFrame, find if there is at least one\n",
    "    seed in the seeds DataFrame sharing at least `ncommon` cids. If found,\n",
    "    store the particle's pt in a list.\n",
    "\n",
    "    Parameters:\n",
    "        particles (pd.DataFrame): Must have columns 'pt' and 'cids'.\n",
    "        seeds (pd.DataFrame): Must have columns 'sid' and 'cids'.\n",
    "        ncommon (int): Threshold for minimum shared cids.\n",
    "\n",
    "    Returns:\n",
    "        list: List of particle pt's that matched at least one seed.\n",
    "    \"\"\"\n",
    "\n",
    "    # Precompute sets of cids for each seed to avoid repeated set() calls\n",
    "    # We'll just store a list of (sid, set_of_cids) so we can iterate quickly.\n",
    "    seed_cid_sets = []\n",
    "    for _, seed_row in seeds.iterrows():\n",
    "        seed_cid_sets.append( (seed_row['sid'], set(seed_row['cids'])) )\n",
    "\n",
    "    matched_pts = []\n",
    "\n",
    "    # Helper function to short-circuit intersection counting\n",
    "    def has_ncommon_or_more(set_a, set_b, n):\n",
    "        \"\"\"\n",
    "        Return True if sets `set_a` and `set_b` share at least `n` elements,\n",
    "        checking incrementally so we can stop early.\n",
    "        \"\"\"\n",
    "        # Always iterate over the smaller set to reduce lookups\n",
    "        if len(set_a) <= len(set_b):\n",
    "            smaller, larger = set_a, set_b\n",
    "        else:\n",
    "            smaller, larger = set_b, set_a\n",
    "\n",
    "        count = 0\n",
    "        for item in smaller:\n",
    "            if item in larger:\n",
    "                count += 1\n",
    "                if count >= n:\n",
    "                    return True\n",
    "        return False\n",
    "\n",
    "    # For each particle, check if at least one seed matches\n",
    "    for _, particle_row in particles.iterrows():\n",
    "        particle_cids = set(particle_row['cids'])\n",
    "        for sid, seed_set in seed_cid_sets:\n",
    "            if has_ncommon_or_more(particle_cids, seed_set, ncommon):\n",
    "                matched_pts.append(particle_row['pt'])\n",
    "                break  # no need to check further seeds once matched\n",
    "\n",
    "    return matched_pts\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `particles` and `seeds` are already defined from get_particles() and get_seeds():\n",
    "ncommon = 6  # change to your desired threshold\n",
    "matched_pt = match_particles_to_seeds_optimized(particles, seeds, ncommon)\n",
    "all_pt = particles['pt'].tolist()\n",
    "print(f\"All {len(all_pt)} matched: {len(matched_pt)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e27cd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Suppose you already have these:\n",
    "# all_pt = particles['pt'].tolist()\n",
    "# matched_pt = match_particles_to_seeds_optimized(particles, seeds, ncommon)\n",
    "\n",
    "# 1) Plot histograms of all_pt and matched_pt\n",
    "bins = 10  # number of bins, or you can use a custom bin array, e.g., np.linspace(0, 10, 11)\n",
    "plt.hist(all_pt, bins=bins, alpha=0.5, label='All')\n",
    "plt.hist(matched_pt, bins=bins, alpha=0.5, label='Matched')\n",
    "plt.xlabel('pt')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of All vs. Matched pT')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 2) Compute Efficiency per bin\n",
    "bin_counts_all, bin_edges = np.histogram(all_pt, bins=bins)\n",
    "bin_counts_matched, _     = np.histogram(matched_pt, bins=bin_edges)\n",
    "\n",
    "# Avoid divide-by-zero by checking bin_counts_all before dividing\n",
    "efficiency = np.zeros_like(bin_counts_all, dtype=float)\n",
    "mask = bin_counts_all > 0\n",
    "efficiency[mask] = bin_counts_matched[mask] / bin_counts_all[mask]\n",
    "\n",
    "# 3) Plot Efficiency vs. pT\n",
    "# Use the bin centers for plotting\n",
    "bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "\n",
    "plt.plot(bin_centers, efficiency, marker='o', linestyle='-')\n",
    "plt.xlabel('pt')\n",
    "plt.ylabel('Efficiency')\n",
    "plt.title('Matching Efficiency vs. pT')\n",
    "plt.ylim(0, 1)  # Efficiency ranges from 0 to 1\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6994015",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myvenv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
